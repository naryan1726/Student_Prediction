import pandas as pd
import re

def clean_dataframes(dataframes_dict):
    """
    Clean extracted dataframes by pulling out relevant data
    
    Args:
        dataframes_dict: Dictionary with dataframe names as keys and dataframes as values
        
    Returns:
        Dictionary with "[original_name]_cleaned" as keys and cleaned dataframes as values
    """
    cleaned_dataframes = {}
    
    for name, df in dataframes_dict.items():
        print(f"Cleaning dataframe: {name}")
        
        # Extract title from rows 2-5
        title = extract_title_from_df(df)
        
        # Find columns for Grade, Job Code, Title if they exist
        columns_info = identify_key_columns(df)
        
        # Find Annual rows and extract start/end rates
        annual_data = extract_annual_data_with_grade_matching(df, columns_info)
        
        # Convert the list of dictionaries to a DataFrame and add category column
        if annual_data:
            result_df = pd.DataFrame(annual_data)
            # Add the title as a category column
            result_df['category'] = title
            
            # Use original name + "_cleaned" as the key
            cleaned_name = f"{name}_cleaned"
            cleaned_dataframes[cleaned_name] = result_df
            print(f"  Successfully cleaned data for: {name}")
        else:
            print(f"  No suitable data found in: {name}")
    
    return cleaned_dataframes

def extract_title_from_df(df):
    """Extract title from rows 2-5 of dataframe"""
    title = ""
    
    # Convert dataframe index to ensure we can access by integer position
    df_copy = df.reset_index(drop=True) if not isinstance(df.index, pd.RangeIndex) else df.copy()
    
    # Look through rows 2-5 (index 1-4) for title
    for i in range(1, 5):
        if i >= len(df_copy):
            break
            
        row = df_copy.iloc[i]
        # Filter out NaN and empty strings, join remaining strings
        title_parts = [str(val).strip() for val in row if pd.notna(val) and str(val).strip() and str(val).upper() != 'NAN']
        
        if title_parts:
            if 'SCHEDULE' in ' '.join(title_parts) or 'BUREAU' in ' '.join(title_parts):
                title += ' '.join(title_parts) + ' '
    
    return title.strip()

def identify_key_columns(df):
    """Find columns for Grade, Job Code, Title"""
    columns_info = {
        'grade_col': None,
        'job_code_col': None,
        'title_col': None,
        'header_row': None
    }
    
    # First, find the header row containing 'Grade' or other key columns
    for i, row in df.iterrows():
        row_values = [str(val).lower() if pd.notna(val) else "" for val in row]
        row_text = " ".join(row_values)
        
        if "grade" in row_text:
            columns_info['header_row'] = i
            # Now identify specific columns in this row
            for j, val in enumerate(row):
                if pd.notna(val):
                    val_str = str(val).lower()
                    if "grade" in val_str:
                        columns_info['grade_col'] = j
                    elif "job" in val_str and "code" in val_str:
                        columns_info['job_code_col'] = j
                    elif "title" in val_str:
                        columns_info['title_col'] = j
            break
    
    return columns_info

def extract_annual_data_with_grade_matching(df, columns_info):
    """Extract annual data with start and end rates, ensuring grades from hourly rows are applied to annual rows"""
    annual_data = []
    
    # If we found a header row
    if columns_info['header_row'] is not None:
        # Create a new dataframe with proper headers
        header_row = columns_info['header_row']
        df_with_headers = df.iloc[header_row+1:].copy()
        df_with_headers.columns = df.iloc[header_row]
        
        # Find term column (containing "Hourly", "Bi-Weekly", "Annual")
        term_col = None
        for i, col in enumerate(df_with_headers.columns):
            term_values = df_with_headers.iloc[:, i].astype(str).str.lower()
            if term_values.str.contains('hourly').any() and term_values.str.contains('annual').any():
                term_col = i
                break
        
        # If we couldn't find a term column, return empty
        if term_col is None:
            return annual_data
        
        # Create a mapping of grades to terms
        grade_term_groups = {}
        current_grade = None
        
        # Process rows to build grade-term relationships
        for idx, row in df_with_headers.iterrows():
            # If we have a grade value, update current_grade
            if columns_info['grade_col'] is not None and pd.notna(row.iloc[columns_info['grade_col']]):
                current_grade = row.iloc[columns_info['grade_col']]
            
            # If we have a grade and term, add to mapping
            if current_grade is not None and pd.notna(row.iloc[term_col]):
                term = str(row.iloc[term_col]).lower()
                if term in ['hourly', 'bi-weekly', 'annual']:
                    if current_grade not in grade_term_groups:
                        grade_term_groups[current_grade] = {}
                    grade_term_groups[current_grade][term] = idx
        
        # Find start rate column (Entry Rate or 1st Step)
        start_rate_col = None
        for col in df_with_headers.columns:
            if pd.notna(col) and isinstance(col, str):
                if "entry rate" in str(col).lower() or "1st step" in str(col).lower():
                    start_rate_col = col
                    break
        
        # Find end rate column (highest step)
        end_rate_col = None
        step_cols = {}
        for col in df_with_headers.columns:
            if pd.notna(col) and isinstance(col, str):
                step_match = re.search(r'(\d+)(th|st|nd|rd)\s+step', str(col).lower())
                if step_match:
                    step_num = int(step_match.group(1))
                    step_cols[step_num] = col
        
        if step_cols:
            highest_step = max(step_cols.keys())
            end_rate_col = step_cols[highest_step]
        
        # Extract annual data using grade mappings
        if start_rate_col and end_rate_col:
            for grade, terms in grade_term_groups.items():
                if 'annual' in terms:
                    annual_idx = terms['annual']
                    row_data = df_with_headers.loc[annual_idx]
                    
                    data_item = {
                        'Grade': grade,  # Use the grade mapped from hourly row
                        'Term': 'Annual',
                        'Start_Rate': row_data[start_rate_col],
                        'End_Rate': row_data[end_rate_col]
                    }
                    
                    # Add job code and title if available
                    if columns_info['job_code_col'] is not None:
                        data_item['Job_Code'] = row_data[columns_info['job_code_col']]
                    if columns_info['title_col'] is not None:
                        data_item['Title'] = row_data[columns_info['title_col']]
                    
                    annual_data.append(data_item)
    
    return annual_data

def find_column(df, column_pattern):
    for i, col in enumerate(df.columns):
        if isinstance(col, str) and column_pattern.lower() in col.lower():
            return i
    return None

def find_first_step_column(df):
    # Try to find "Entry Rate" first (including variations like "Entry Rate 1")
    for pattern in ["entry rate", "entry rate 1"]:
        entry_col = find_column(df, pattern)
        if entry_col is not None:
            return entry_col
    
    # If not found, try to find "1st Step"
    return find_column(df, "1st step")

def find_last_step_column(df):
    step_columns = []
    for i, col in enumerate(df.columns):
        if isinstance(col, str) and re.search(r'\d+th step', col.lower()):
            step_number = int(re.search(r'(\d+)th', col.lower()).group(1))
            step_columns.append((step_number, i))
    
    if step_columns:
        # Sort by step number and get the highest
        return sorted(step_columns, key=lambda x: x[0], reverse=True)[0][1]
    return None

# Example usage:
# Assuming you have a dictionary of already extracted dataframes
# extracted_dataframes = {'df1': df1, 'df2': df2, ...}
# cleaned_dataframes = clean_dataframes(extracted_dataframes)